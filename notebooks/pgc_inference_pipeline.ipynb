{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thK7r17Bj1uZ"
   },
   "source": [
    "# PGCView Image Prediction Pipeline\n",
    "This Python notebook will allow you to load the PGC View model API endpoints, upload your images, and then process them.\n",
    "\n",
    "Instructions:\n",
    "* Connect to a CPU instance using the menu at the top right of the notebook (no need to use a GPU runtime)\n",
    "* Once connected, go to the 'Files' directory on the left sidebar and upload all your images in 'RGPCV_fastapi/assets/images'\n",
    "* Click 'run' on each cell or use the toolbar and got to  'Runtime' -> 'Run all'\n",
    "* Wait for all the images to finish processing and then download image predictions and tabular data from 'output'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sbrWA-WiTpEa"
   },
   "source": [
    "## Step 1\n",
    "Run the cell below to mount your Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22119,
     "status": "ok",
     "timestamp": 1742825931844,
     "user": {
      "displayName": "Bo Meyering",
      "userId": "12820085305614794448"
     },
     "user_tz": 240
    },
    "id": "OCXVN116akYx",
    "outputId": "f7ef7db2-e8dc-464f-cee8-090bc45e13dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0EGHnmIxTpEd"
   },
   "source": [
    "## Step 2\n",
    "Clone the GitHub repository for the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3351,
     "status": "ok",
     "timestamp": 1742825941415,
     "user": {
      "displayName": "Bo Meyering",
      "userId": "12820085305614794448"
     },
     "user_tz": 240
    },
    "id": "zOT1z6oKtkbw",
    "outputId": "6fb91606-e737-4224-8b05-ab52ee7c8265"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'regen_pgc_inference_pipeline'...\n",
      "remote: Enumerating objects: 113, done.\u001b[K\n",
      "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
      "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
      "remote: Total 113 (delta 12), reused 20 (delta 6), pack-reused 83 (from 1)\u001b[K\n",
      "Receiving objects: 100% (113/113), 41.93 MiB | 19.02 MiB/s, done.\n",
      "Resolving deltas: 100% (49/49), done.\n",
      "/content/regen_pgc_inference_pipeline\n"
     ]
    }
   ],
   "source": [
    "# Grab the pipeline code from GitHub\n",
    "!git clone https://github.com/BoMeyering/regen_pgc_inference_pipeline.git\n",
    "%cd regen_pgc_inference_pipeline/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bomeyering/Insync/meyering@landinstitute.org/Google Drive/github_repos/regen_pgc_inference_pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bomeyering/.pyenv/versions/3.11.8/envs/torch_env/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 9048,
     "status": "ok",
     "timestamp": 1742825950465,
     "user": {
      "displayName": "Bo Meyering",
      "userId": "12820085305614794448"
     },
     "user_tz": 240
    },
    "id": "lFqariJFbaSP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bomeyering/.pyenv/versions/3.11.8/envs/torch_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pipeline import run_pipeline, get_filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inh6VA2BTpEf"
   },
   "source": [
    " ## Step 3\n",
    "Once all the above cells have run successfully, add all of your images into ```assets/images```. Wait for the uploads to finish, and then run the cell below.\n",
    "It should output a list of all the images names like\n",
    "\n",
    "```\n",
    "['image_1.jpg', 'image_2.jpg', ... , 'image_n.jpg']\n",
    "```\n",
    "\n",
    "If there is no output or if the output is an empty list ```[]```, then you uploaded your images to the wrong directory.\n",
    "\n",
    "\n",
    "UPDATE: If you have images stored in Google Drive and don't want to download them locally before reuploading them, uncomment the line below that says\n",
    "```\n",
    "#CUSTOM_DIR = \"PATH/TO/YOUR/IMAGES/HERE\"\n",
    "```\n",
    "\n",
    "and replace with the path to your images in Google Drive like so\n",
    "```\n",
    "CUSTOM_DIR = 'drive/MyDrive/pgc_project/images'  # Example only\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 97,
     "status": "ok",
     "timestamp": 1742354779194,
     "user": {
      "displayName": "Bo Meyering",
      "userId": "12820085305614794448"
     },
     "user_tz": 240
    },
    "id": "MhM1BH7wf4OD",
    "outputId": "ee3acd3b-19bc-4501-8334-fe604771d118"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IMG_0545_crop.jpeg',\n",
       " 'IMG_0533.jpeg',\n",
       " 'IMG_0536.jpeg',\n",
       " 'IMG_0546_crop.jpeg',\n",
       " 'IMG_0533_crop.jpeg']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IF YOUR IMAGES ARE IN 'assets/images'\n",
    "img_filenames = get_filenames()\n",
    "img_filenames['filenames']\n",
    "\n",
    "# Grab all of the image filenames in 'assets/images'\n",
    "\n",
    "# CUSTOM_DIR = \"PATH/TO/YOUR/IMAGES/HERE\"\n",
    "# img_filenames = get_filenames(CUSTOM_DIR)\n",
    "# img_filenames['filenames']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEpfL5wgTpEg"
   },
   "source": [
    "## Step 4\n",
    "Run the cell below. This sends each of the images in ```images``` list to the model API and sends the results to the image analysis pipeline.\n",
    "\n",
    "This step might take a long time to complete (15-20 seconds per image) depending on the type of server connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 62448,
     "status": "ok",
     "timestamp": 1742354843595,
     "user": {
      "displayName": "Bo Meyering",
      "userId": "12820085305614794448"
     },
     "user_tz": 240
    },
    "id": "iEUX49yc_NB8",
    "outputId": "9836528e-9f85-40d1-b9cd-45d4588b5304"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing image IMG_0545_crop.jpeg:   0%|          | 0/5 [00:00<?, ?it/s]/content/regen_pgc_inference_pipeline/pipeline.py:206: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, prop_df], ignore_index=True)\n",
      "Processing image IMG_0533.jpeg:  20%|██        | 1/5 [00:12<00:48, 12.10s/it]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fewer than 2 markers predicted, returning predictions over entire image.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing image IMG_0536.jpeg:  40%|████      | 2/5 [00:25<00:37, 12.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fewer than 2 markers predicted, returning predictions over entire image.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing image IMG_0546_crop.jpeg:  60%|██████    | 3/5 [00:36<00:24, 12.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fewer than 2 markers predicted, returning predictions over entire image.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing image IMG_0533_crop.jpeg:  80%|████████  | 4/5 [00:50<00:12, 12.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fewer than 2 markers predicted, returning predictions over entire image.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing image IMG_0533_crop.jpeg: 100%|██████████| 5/5 [01:02<00:00, 12.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fewer than 2 markers predicted, returning predictions over entire image.\n",
      "             filename num_markers prediction_zone  background   quadrat  \\\n",
      "0  IMG_0545_crop.jpeg           0     whole_image    0.005184  0.000000   \n",
      "1       IMG_0533.jpeg           0     whole_image    0.081398  0.000226   \n",
      "2       IMG_0536.jpeg           0     whole_image    0.009245  0.000000   \n",
      "3  IMG_0546_crop.jpeg           0     whole_image    0.021147  0.000627   \n",
      "4  IMG_0533_crop.jpeg           0     whole_image    0.136616  0.000964   \n",
      "\n",
      "   pgc_grass  pgc_clover  broadleaf_weed     maize  soybean  other_vegetation  \\\n",
      "0   0.181786    0.608807        0.204224  0.000000      0.0               0.0   \n",
      "1   0.795922    0.027319        0.095135  0.000000      0.0               0.0   \n",
      "2   0.990287    0.000000        0.000000  0.000468      0.0               0.0   \n",
      "3   0.946517    0.025633        0.006045  0.000031      0.0               0.0   \n",
      "4   0.820470    0.031372        0.010527  0.000051      0.0               0.0   \n",
      "\n",
      "   active_grass  dormant_grass  \n",
      "0      0.971404       0.028596  \n",
      "1      0.495654       0.504346  \n",
      "2      0.000002       0.999998  \n",
      "3      0.997553       0.002447  \n",
      "4      0.559848       0.440152  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the image analysis pipeline\n",
    "run_pipeline(img_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PzzidrWZKlwL"
   },
   "source": [
    "## Step 5\n",
    "After the ```run_pipeline``` function is finished, you can check the model outputs in ```outputs/```"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
